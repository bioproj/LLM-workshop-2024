{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "45398736-7e89-4263-89c8-92153baff553",
      "metadata": {
        "id": "45398736-7e89-4263-89c8-92153baff553"
      },
      "source": [
        "**LLM Workshop 2024 by Sebastian Raschka**\n",
        "\n",
        "This code is based on *Build a Large Language Model (From Scratch)*, [https://github.com/rasbt/LLMs-from-scratch](https://github.com/rasbt/LLMs-from-scratch)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66dd524e-864c-4012-b0a2-ccfc56e80024",
      "metadata": {
        "id": "66dd524e-864c-4012-b0a2-ccfc56e80024"
      },
      "source": [
        "# 4) Pretraining LLMs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/bioproj/LLM-workshop-2024/refs/heads/main/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1XklNSmuty-",
        "outputId": "b68770db-50d4-43e5-e304-3f230ecaf7f7"
      },
      "id": "Z1XklNSmuty-",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-03-01 11:01:05--  https://raw.githubusercontent.com/bioproj/LLM-workshop-2024/refs/heads/main/requirements.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 197 [text/plain]\n",
            "Saving to: ‘requirements.txt’\n",
            "\n",
            "requirements.txt    100%[===================>]     197  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-01 11:01:05 (9.37 MB/s) - ‘requirements.txt’ saved [197/197]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "FATtVkL4u-My",
        "outputId": "8d305b34-891c-4350-d9dc-be19e43077dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "FATtVkL4u-My",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.5.1+cu124)\n",
            "Collecting jupyterlab>=4.0 (from -r requirements.txt (line 2))\n",
            "  Downloading jupyterlab-4.3.5-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting tiktoken>=0.5.1 (from -r requirements.txt (line 3))\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.26.4)\n",
            "Requirement already satisfied: tensorflow>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (2.18.0)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (4.67.1)\n",
            "Requirement already satisfied: pandas>=2.2.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (2.2.2)\n",
            "Requirement already satisfied: psutil>=5.9.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
            "Collecting litgpt>=0.4.1 (from litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading litgpt-0.5.7-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->-r requirements.txt (line 1)) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->-r requirements.txt (line 1)) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->-r requirements.txt (line 1)) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->-r requirements.txt (line 1)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.1->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.1->-r requirements.txt (line 1)) (1.3.0)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab>=4.0->-r requirements.txt (line 2))\n",
            "  Downloading async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->-r requirements.txt (line 2)) (0.28.1)\n",
            "Requirement already satisfied: ipykernel>=6.5.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->-r requirements.txt (line 2)) (6.17.1)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->-r requirements.txt (line 2)) (5.7.2)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab>=4.0->-r requirements.txt (line 2))\n",
            "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab>=4.0->-r requirements.txt (line 2))\n",
            "  Downloading jupyter_server-2.15.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab>=4.0->-r requirements.txt (line 2))\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->-r requirements.txt (line 2)) (0.2.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->-r requirements.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->-r requirements.txt (line 2)) (75.1.0)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->-r requirements.txt (line 2)) (6.4.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->-r requirements.txt (line 2)) (5.7.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.5.1->-r requirements.txt (line 3)) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.5.1->-r requirements.txt (line 3)) (2.32.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->-r requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->-r requirements.txt (line 4)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->-r requirements.txt (line 4)) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->-r requirements.txt (line 4)) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->-r requirements.txt (line 4)) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 6)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 6)) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 6)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 6)) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 6)) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 6)) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 6)) (4.25.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 6)) (2.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 6)) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 6)) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 6)) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 6)) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 6)) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 6)) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.15.0->-r requirements.txt (line 6)) (0.37.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.1->-r requirements.txt (line 9)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.1->-r requirements.txt (line 9)) (2025.1)\n",
            "Collecting lightning<2.6.0,>=2.5.0 (from litgpt>=0.4.1->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading lightning-2.5.0.post0-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonargparse<=4.32.1,>=4.30.1 (from jsonargparse[signatures]<=4.32.1,>=4.30.1->litgpt>=0.4.1->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading jsonargparse-4.32.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: huggingface_hub>=0.23.5 in /usr/local/lib/python3.11/dist-packages (from litgpt>=0.4.1->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (0.28.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from litgpt>=0.4.1->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (0.5.3)\n",
            "Requirement already satisfied: tokenizers>=0.15.2 in /usr/local/lib/python3.11/dist-packages (from litgpt>=0.4.1->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (0.21.0)\n",
            "Collecting lightning-thunder>=0.2.0.dev20250119 (from litgpt>=0.4.1->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading lightning_thunder-0.2.2.dev20250223-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting bitsandbytes<0.44.2,>=0.44.0 (from litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (0.2.0)\n",
            "Collecting litdata==0.2.17 (from litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading litdata-0.2.17-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting litserve<=0.2.4 (from litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading litserve-0.2.4-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: zstandard>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (0.23.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.2 in /usr/local/lib/python3.11/dist-packages (from litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (18.1.0)\n",
            "Collecting torchmetrics>=1.3.1 (from litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting datasets>=2.18.0 (from litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting transformers==4.47.1 (from litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lm-eval>=0.4.2 (from litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading lm_eval-0.4.7-py3-none-any.whl.metadata (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvloop>=0.2.0 (from litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting boto3 (from litdata==0.2.17->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading boto3-1.37.4-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.1->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (6.0.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=2.15.0->-r requirements.txt (line 6)) (0.45.1)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.18.0->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from datasets>=2.18.0->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.18.0->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.18.0->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (3.11.13)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (0.14.0)\n",
            "Collecting hf-transfer>=0.1.4 (from huggingface_hub[hf_transfer]>=0.21.0; extra == \"all\"->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (1.6.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (24.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.1->-r requirements.txt (line 1)) (3.0.2)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from jsonargparse[signatures]<=4.32.1,>=4.30.1->litgpt>=0.4.1->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (0.16)\n",
            "Collecting typeshed-client>=2.1.0 (from jsonargparse[signatures]<=4.32.1,>=4.30.1->litgpt>=0.4.1->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading typeshed_client-2.7.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (23.1.0)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel>=6.5.0->jupyterlab>=4.0->-r requirements.txt (line 2))\n",
            "  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2))\n",
            "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2))\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (7.16.6)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (5.10.4)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2))\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (0.21.1)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (0.18.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (1.8.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab>=4.0->-r requirements.txt (line 2)) (4.3.6)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->-r requirements.txt (line 2)) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->-r requirements.txt (line 2))\n",
            "  Downloading json5-0.10.0-py3-none-any.whl.metadata (34 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->-r requirements.txt (line 2)) (4.23.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.15.0->-r requirements.txt (line 6)) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.15.0->-r requirements.txt (line 6)) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.15.0->-r requirements.txt (line 6)) (0.14.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<2.6.0,>=2.5.0->litgpt>=0.4.1->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading lightning_utilities-0.12.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting pytorch-lightning (from lightning<2.6.0,>=2.5.0->litgpt>=0.4.1->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading pytorch_lightning-2.5.0.post0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting looseversion==1.3.0 (from lightning-thunder>=0.2.0.dev20250119->litgpt>=0.4.1->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading looseversion-1.3.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting fastapi>=0.100 (from litserve<=0.2.4->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading fastapi-0.115.10-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.29.0 (from uvicorn[standard]>=0.29.0->litserve<=0.2.4->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from lm-eval>=0.4.2->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (1.3.0)\n",
            "Collecting evaluate (from lm-eval>=0.4.2->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting jsonlines (from lm-eval>=0.4.2->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from lm-eval>=0.4.2->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (2.10.2)\n",
            "Requirement already satisfied: peft>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from lm-eval>=0.4.2->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (0.14.0)\n",
            "Collecting pybind11>=2.6.2 (from lm-eval>=0.4.2->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting pytablewriter (from lm-eval>=0.4.2->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading pytablewriter-1.2.1-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting rouge-score>=0.0.4 (from lm-eval>=0.4.2->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu>=1.5.0 (from lm-eval>=0.4.2->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from lm-eval>=0.4.2->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (1.6.1)\n",
            "Collecting sqlitedict (from lm-eval>=0.4.2->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tqdm-multiprocess (from lm-eval>=0.4.2->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting word2number (from lm-eval>=0.4.2->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.11/dist-packages (from lm-eval>=0.4.2->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (10.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.5.1->-r requirements.txt (line 3)) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.5.1->-r requirements.txt (line 3)) (2.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.15.0->-r requirements.txt (line 6)) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.15.0->-r requirements.txt (line 6)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.15.0->-r requirements.txt (line 6)) (3.1.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (21.2.0)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi>=0.100->litserve<=0.2.4->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading starlette-0.46.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.100->litserve<=0.2.4->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (2.10.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.18.0->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.18.0->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.18.0->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.18.0->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.18.0->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.18.0->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.18.0->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (1.18.3)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->-r requirements.txt (line 2))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (4.9.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->-r requirements.txt (line 2)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->-r requirements.txt (line 2)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->-r requirements.txt (line 2)) (0.23.1)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2))\n",
            "  Downloading python_json_logger-3.2.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2))\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2))\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (4.13.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (3.1.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (2.21.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm-eval>=0.4.2->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (3.9.1)\n",
            "Collecting portalocker (from sacrebleu>=1.5.0->lm-eval>=0.4.2->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm-eval>=0.4.2->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (0.9.0)\n",
            "Collecting colorama (from sacrebleu>=1.5.0->lm-eval>=0.4.2->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm-eval>=0.4.2->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (5.3.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm-eval>=0.4.2->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm-eval>=0.4.2->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm-eval>=0.4.2->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (3.5.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from typeshed-client>=2.1.0->jsonargparse[signatures]<=4.32.1,>=4.30.1->litgpt>=0.4.1->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (6.5.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.29.0->uvicorn[standard]>=0.29.0->litserve<=0.2.4->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (8.1.8)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.29.0->litserve<=0.2.4->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.29.0->litserve<=0.2.4->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.29.0->litserve<=0.2.4->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.29.0->litserve<=0.2.4->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (14.2)\n",
            "Collecting botocore<1.38.0,>=1.37.4 (from boto3->litdata==0.2.17->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading botocore-1.37.4-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->litdata==0.2.17->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3->litdata==0.2.17->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading s3transfer-0.11.3-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting DataProperty<2,>=1.1.0 (from pytablewriter->lm-eval>=0.4.2->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading DataProperty-1.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm-eval>=0.4.2->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading mbstrdecoder-1.1.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm-eval>=0.4.2->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading pathvalidate-3.2.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm-eval>=0.4.2->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading tabledata-1.3.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm-eval>=0.4.2->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading tcolorpy-0.1.7-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval>=0.4.2->litgpt[all]>=0.4.1->-r requirements.txt (line 11))\n",
            "  Downloading typepy-1.3.4-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.15.0->-r requirements.txt (line 6)) (3.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (0.8.4)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2))\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2))\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (3.0.0)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2))\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (24.11.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.15.0->-r requirements.txt (line 6)) (0.1.2)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.11/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm-eval>=0.4.2->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (5.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (0.2.13)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi>=0.100->litserve<=0.2.4->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi>=0.100->litserve<=0.2.4->litgpt[all]>=0.4.1->-r requirements.txt (line 11)) (2.27.2)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2)) (2.22)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2))\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->-r requirements.txt (line 2))\n",
            "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m109.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab-4.3.5-py3-none-any.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m115.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading litgpt-0.5.7-py3-none-any.whl (176 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.6/176.6 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading litdata-0.2.17-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.7/125.7 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
            "Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonargparse-4.32.1-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server-2.15.0-py3-none-any.whl (385 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.5.0.post0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_thunder-0.2.2.dev20250223-py3-none-any.whl (862 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m862.8/862.8 kB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading looseversion-1.3.0-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading litserve-0.2.4-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lm_eval-0.4.7-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.10-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.10.0-py3-none-any.whl (34 kB)\n",
            "Downloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
            "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Downloading lightning_utilities-0.12.0-py3-none-any.whl (28 kB)\n",
            "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeshed_client-2.7.0-py3-none-any.whl (624 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m624.4/624.4 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.37.4-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading pytablewriter-1.2.1-py3-none-any.whl (91 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.0.post0-py3-none-any.whl (819 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.3/819.3 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.37.4-py3-none-any.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m112.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading DataProperty-1.1.0-py3-none-any.whl (27 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading mbstrdecoder-1.1.4-py3-none-any.whl (7.9 kB)\n",
            "Downloading pathvalidate-3.2.3-py3-none-any.whl (24 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading python_json_logger-3.2.1-py3-none-any.whl (14 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading s3transfer-0.11.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.2/84.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.46.0-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tabledata-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading tcolorpy-0.1.7-py3-none-any.whl (8.1 kB)\n",
            "Downloading typepy-1.3.4-py3-none-any.whl (31 kB)\n",
            "Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: rouge-score, sqlitedict, word2number\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=b53dac8e10866bd6cd61e4313d59cfebc8e8dcd25d2eef0201f6dc2ecbfe0a37\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16864 sha256=716ca84eb072c4733dac2f6cb2bd5181e30984ee348f7b447b758054ed3ae3bf\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/63/89/7210274f9b7fb033b8f22671f64c0e0b55083d30c3c046a3ff\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5568 sha256=925ee94d0863caa46ff6fab92c19b4b504a2d8d65ba024993c4e2870e3d92a38\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/ef/ae/073b491b14d25e2efafcffca9e16b2ee6d114ec5c643ba4f06\n",
            "Successfully built rouge-score sqlitedict word2number\n",
            "Installing collected packages: word2number, sqlitedict, looseversion, xxhash, uvloop, uvicorn, uri-template, typeshed-client, types-python-dateutil, tcolorpy, rfc3986-validator, rfc3339-validator, python-json-logger, python-dotenv, pybind11, portalocker, pathvalidate, overrides, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mbstrdecoder, lightning-utilities, jsonlines, jsonargparse, json5, jmespath, jedi, httptools, hf-transfer, fqdn, dill, colorama, async-lru, watchfiles, typepy, tqdm-multiprocess, tiktoken, starlette, sacrebleu, rouge-score, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, jupyter-server-terminals, jupyter-client, botocore, arrow, s3transfer, nvidia-cusolver-cu12, isoduration, fastapi, transformers, litserve, datasets, DataProperty, boto3, torchmetrics, tabledata, litdata, lightning-thunder, jupyter-events, evaluate, bitsandbytes, pytorch-lightning, pytablewriter, lm-eval, lightning, jupyter-server, litgpt, jupyterlab-server, jupyter-lsp, jupyterlab\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.48.3\n",
            "    Uninstalling transformers-4.48.3:\n",
            "      Successfully uninstalled transformers-4.48.3\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.24.0\n",
            "    Uninstalling jupyter-server-1.24.0:\n",
            "      Successfully uninstalled jupyter-server-1.24.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "notebook 6.5.5 requires jupyter-client<8,>=5.3.4, but you have jupyter-client 8.6.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed DataProperty-1.1.0 arrow-1.3.0 async-lru-2.0.4 bitsandbytes-0.44.1 boto3-1.37.4 botocore-1.37.4 colorama-0.4.6 datasets-3.3.2 dill-0.3.8 evaluate-0.4.3 fastapi-0.115.10 fqdn-1.5.1 hf-transfer-0.1.9 httptools-0.6.4 isoduration-20.11.0 jedi-0.19.2 jmespath-1.0.1 json5-0.10.0 jsonargparse-4.32.1 jsonlines-4.0.0 jupyter-client-8.6.3 jupyter-events-0.12.0 jupyter-lsp-2.2.5 jupyter-server-2.15.0 jupyter-server-terminals-0.5.3 jupyterlab-4.3.5 jupyterlab-server-2.27.3 lightning-2.5.0.post0 lightning-thunder-0.2.2.dev20250223 lightning-utilities-0.12.0 litdata-0.2.17 litgpt-0.5.7 litserve-0.2.4 lm-eval-0.4.7 looseversion-1.3.0 mbstrdecoder-1.1.4 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 overrides-7.7.0 pathvalidate-3.2.3 portalocker-3.1.1 pybind11-2.13.6 pytablewriter-1.2.1 python-dotenv-1.0.1 python-json-logger-3.2.1 pytorch-lightning-2.5.0.post0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rouge-score-0.1.2 s3transfer-0.11.3 sacrebleu-2.5.1 sqlitedict-2.1.0 starlette-0.46.0 tabledata-1.3.4 tcolorpy-0.1.7 tiktoken-0.9.0 torchmetrics-1.6.1 tqdm-multiprocess-0.0.11 transformers-4.47.1 typepy-1.3.4 types-python-dateutil-2.9.0.20241206 typeshed-client-2.7.0 uri-template-1.3.0 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.4 word2number-1.1 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "92b989e9-da36-4159-b212-799184764dd9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92b989e9-da36-4159-b212-799184764dd9",
        "outputId": "245c86a5-14de-4959-9b0e-194de2c73d2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matplotlib version: 3.10.0\n",
            "numpy version: 1.26.4\n",
            "tiktoken version: 0.9.0\n",
            "torch version: 2.5.1+cu124\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "pkgs = [\"matplotlib\",\n",
        "        \"numpy\",\n",
        "        \"tiktoken\",\n",
        "        \"torch\",\n",
        "       ]\n",
        "for p in pkgs:\n",
        "    print(f\"{p} version: {version(p)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a3bdf9e-2ff0-4a57-abab-ede2d955a237",
      "metadata": {
        "id": "0a3bdf9e-2ff0-4a57-abab-ede2d955a237"
      },
      "source": [
        "- In this notebook, we implement the training loop and code for basic model evaluation to pretrain an LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efd27fcc-2886-47cb-b544-046c2c31f02a",
      "metadata": {
        "id": "efd27fcc-2886-47cb-b544-046c2c31f02a"
      },
      "source": [
        "<img src=\"https://github.com/bioproj/LLM-workshop-2024/blob/main/04_pretraining/figures/01.png?raw=1\" width=1000px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdc1cf3f-82d8-46c7-9ecc-58979ce87cdd",
      "metadata": {
        "id": "bdc1cf3f-82d8-46c7-9ecc-58979ce87cdd"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "# 4.1 Using GPT to generate text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b3415fd-9f4a-4548-908e-9dfa56edc9bc",
      "metadata": {
        "id": "5b3415fd-9f4a-4548-908e-9dfa56edc9bc"
      },
      "source": [
        "- We initialize a GPT model using the code from the previous notebook"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/bioproj/LLM-workshop-2024/refs/heads/main/04_pretraining/supplementary.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S93Ux-B8vtUB",
        "outputId": "f19baf90-d7d8-4cf2-e7e0-33ff96b5693c"
      },
      "id": "S93Ux-B8vtUB",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-01 11:15:29--  https://raw.githubusercontent.com/bioproj/LLM-workshop-2024/refs/heads/main/04_pretraining/supplementary.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11538 (11K) [text/plain]\n",
            "Saving to: ‘supplementary.py’\n",
            "\n",
            "supplementary.py    100%[===================>]  11.27K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-01 11:15:29 (81.4 MB/s) - ‘supplementary.py’ saved [11538/11538]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "86000d74-624a-48f0-86da-f41926cb9e04",
      "metadata": {
        "id": "86000d74-624a-48f0-86da-f41926cb9e04"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from supplementary import GPTModel\n",
        "\n",
        "\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,   # Vocabulary size\n",
        "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
        "    \"emb_dim\": 768,        # Embedding dimension\n",
        "    \"n_heads\": 12,         # Number of attention heads\n",
        "    \"n_layers\": 12,        # Number of layers\n",
        "    \"drop_rate\": 0.1,      # Dropout rate\n",
        "    \"qkv_bias\": False      # Query-key-value bias\n",
        "}\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.eval();  # Disable dropout during inference"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09c6cf0f-7458-48a2-97fd-aa5068d65e8c",
      "metadata": {
        "id": "09c6cf0f-7458-48a2-97fd-aa5068d65e8c"
      },
      "source": [
        "- We use dropout of 0.1 above, but it's relatively common to train LLMs without dropout nowadays\n",
        "- Modern LLMs also don't use bias vectors in the `nn.Linear` layers for the query, key, and value matrices (unlike earlier GPT models), which is achieved by setting `\"qkv_bias\": False`\n",
        "- We reduce the context length (`context_length`) of only 256 tokens to reduce the computational resource requirements for training the model, whereas the original 124 million parameter GPT-2 model used 1024 tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59f80895-be35-4bb5-81cb-f357ef7367fe",
      "metadata": {
        "id": "59f80895-be35-4bb5-81cb-f357ef7367fe"
      },
      "source": [
        "- Next, we use the `generate_text_simple` function from the previous chapter to generate text\n",
        "- In addition, we define two convenience functions, `text_to_token_ids` and `token_ids_to_text`, for converting between token and text representations that we use throughout this chapter"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "741881f3-cee0-49ad-b11d-b9df3b3ac234",
      "metadata": {
        "id": "741881f3-cee0-49ad-b11d-b9df3b3ac234"
      },
      "source": [
        "<img src=\"https://github.com/bioproj/LLM-workshop-2024/blob/main/04_pretraining/figures/02.png?raw=1\" width=1200px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5e062b82-3540-48ce-8eb4-009686d0d16c",
      "metadata": {
        "id": "5e062b82-3540-48ce-8eb4-009686d0d16c"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "from supplementary import generate_text_simple\n",
        "\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6516f757-849c-468f-88f7-28ac9debf6be",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6516f757-849c-468f-88f7-28ac9debf6be",
        "outputId": "c4b62851-05fe-43c7-92b3-cdd80853517f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
          ]
        }
      ],
      "source": [
        "start_context = \"Every effort moves you\"\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(start_context, tokenizer),\n",
        "    max_new_tokens=10,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4d3249b-b2a0-44c4-b589-ae4b403b8305",
      "metadata": {
        "id": "e4d3249b-b2a0-44c4-b589-ae4b403b8305"
      },
      "source": [
        "- As we can see above, the model does not produce good text because it has not been trained yet\n",
        "- How do we measure or capture what \"good text\" is, in a numeric form, to track it during training?\n",
        "- The next subsection introduces metrics to calculate a loss metric for the generated outputs that we can use to measure the training progress\n",
        "- The next chapters on finetuning LLMs will also introduce additional ways to measure model quality"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "955f9e1a-7bf7-40d8-b1fa-eacabdee8d8e",
      "metadata": {
        "id": "955f9e1a-7bf7-40d8-b1fa-eacabdee8d8e"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ec6c217-e429-40c7-ad71-5d0a9da8e487",
      "metadata": {
        "id": "2ec6c217-e429-40c7-ad71-5d0a9da8e487"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "# 4.2 Preparing the dataset loaders"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "530da89e-2448-436c-8f1b-28e8a31ef85c",
      "metadata": {
        "id": "530da89e-2448-436c-8f1b-28e8a31ef85c"
      },
      "source": [
        "- We use a relatively small dataset for training the LLM (in fact, only one short story)\n",
        "  - The training finishes relatively fast (minutes instead of weeks), which is good for educational purposes\n",
        "- For example, Llama 2 7B required 184,320 GPU hours on A100 GPUs to be trained on 2 trillion tokens\n",
        "\n",
        "- Below, we use the same dataset we used in the data preparation notebook earlier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/bioproj/LLM-workshop-2024/refs/heads/main/04_pretraining/the-verdict.txt"
      ],
      "metadata": {
        "id": "V4NcrKoYxzPa",
        "outputId": "125eea44-5ed7-4ed5-e605-910a45858cbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "V4NcrKoYxzPa",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-01 11:15:59--  https://raw.githubusercontent.com/bioproj/LLM-workshop-2024/refs/heads/main/04_pretraining/the-verdict.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20479 (20K) [text/plain]\n",
            "Saving to: ‘the-verdict.txt’\n",
            "\n",
            "the-verdict.txt     100%[===================>]  20.00K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-01 11:16:00 (125 MB/s) - ‘the-verdict.txt’ saved [20479/20479]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "654fde37-b2a9-4a20-a8d3-0206c056e2ff",
      "metadata": {
        "id": "654fde37-b2a9-4a20-a8d3-0206c056e2ff"
      },
      "outputs": [],
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    text_data = file.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "379330f1-80f4-4e34-8724-41d892b04cee",
      "metadata": {
        "id": "379330f1-80f4-4e34-8724-41d892b04cee"
      },
      "source": [
        "- A quick check that the text loaded ok by printing the first and last 100 words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6kgJbe4ehI4q",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kgJbe4ehI4q",
        "outputId": "a6345ab7-1ac2-469c-b22a-8d9be0c241d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ],
      "source": [
        "# First 100 characters\n",
        "print(text_data[:99])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "j2XPde_ThM_e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2XPde_ThM_e",
        "outputId": "23599407-081e-41c9-ca46-c9be0e3d44c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
          ]
        }
      ],
      "source": [
        "# Last 100 characters\n",
        "print(text_data[-99:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6b46a952-d50a-4837-af09-4095698f7fd1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b46a952-d50a-4837-af09-4095698f7fd1",
        "outputId": "0e269373-8166-4f44-df3a-d010f5f3fe13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Characters: 20479\n",
            "Tokens: 5145\n"
          ]
        }
      ],
      "source": [
        "total_characters = len(text_data)\n",
        "total_tokens = len(tokenizer.encode(text_data))\n",
        "\n",
        "print(\"Characters:\", total_characters)\n",
        "print(\"Tokens:\", total_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8830cb9-90f6-4e7c-8620-beeabc2d39f7",
      "metadata": {
        "id": "a8830cb9-90f6-4e7c-8620-beeabc2d39f7"
      },
      "source": [
        "- With 5,145 tokens, the text is very short for training an LLM, but again, it's for educational purposes (we will also load pretrained weights later)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bedcad87-a0e8-4b9d-ac43-4e927ccbb50f",
      "metadata": {
        "id": "bedcad87-a0e8-4b9d-ac43-4e927ccbb50f"
      },
      "source": [
        "- Next, we divide the dataset into a training and a validation set and use the data loaders from chapter 2 to prepare the batches for LLM training\n",
        "- For visualization purposes, the figure below assumes a `max_length=6`, but for the training loader, we set the `max_length` equal to the context length that the LLM supports\n",
        "- The figure below only shows the input tokens for simplicity\n",
        "    - Since we train the LLM to predict the next word in the text, the targets look the same as these inputs, except that the targets are shifted by one position"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46bdaa07-ba96-4ac1-9d71-b3cc153910d9",
      "metadata": {
        "id": "46bdaa07-ba96-4ac1-9d71-b3cc153910d9"
      },
      "source": [
        "<img src=\"https://github.com/bioproj/LLM-workshop-2024/blob/main/04_pretraining/figures/03.png?raw=1\" width=1500px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0959c855-f860-4358-8b98-bc654f047578",
      "metadata": {
        "id": "0959c855-f860-4358-8b98-bc654f047578"
      },
      "outputs": [],
      "source": [
        "from supplementary import create_dataloader_v1\n",
        "\n",
        "\n",
        "# Train/validation ratio\n",
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio * len(text_data))\n",
        "train_data = text_data[:split_idx]\n",
        "val_data = text_data[split_idx:]\n",
        "\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = create_dataloader_v1(\n",
        "    train_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=True,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_loader = create_dataloader_v1(\n",
        "    val_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=False,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7ac3296-a4d1-4303-9ac5-376518960c33",
      "metadata": {
        "id": "e7ac3296-a4d1-4303-9ac5-376518960c33"
      },
      "source": [
        "- We use a relatively small batch size to reduce the computational resource demand, and because the dataset is very small to begin with\n",
        "- Llama 2 7B was trained with a batch size of 1024, for example"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8e0514d-b990-4dc0-9afb-7721993284a0",
      "metadata": {
        "id": "a8e0514d-b990-4dc0-9afb-7721993284a0"
      },
      "source": [
        "- An optional check that the data was loaded correctly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ca0116d0-d229-472c-9fbf-ebc229331c3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca0116d0-d229-472c-9fbf-ebc229331c3e",
        "outputId": "8b6477de-be32-400b-c86e-68dc0da52bf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "\n",
            "Validation loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n"
          ]
        }
      ],
      "source": [
        "print(\"Train loader:\")\n",
        "for x, y in train_loader:\n",
        "    print(x.shape, y.shape)\n",
        "\n",
        "print(\"\\nValidation loader:\")\n",
        "for x, y in val_loader:\n",
        "    print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7b9b1a4-863d-456f-a8dd-c07fb5c024ed",
      "metadata": {
        "id": "f7b9b1a4-863d-456f-a8dd-c07fb5c024ed"
      },
      "source": [
        "- Another optional check that the token sizes are in the expected ballpark:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "eb860488-5453-41d7-9870-23b723f742a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb860488-5453-41d7-9870-23b723f742a0",
        "outputId": "cdeefffa-5d8f-4a6c-ac46-347723a43f45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training tokens: 4608\n",
            "Validation tokens: 512\n",
            "All tokens: 5120\n"
          ]
        }
      ],
      "source": [
        "train_tokens = 0\n",
        "for input_batch, target_batch in train_loader:\n",
        "    train_tokens += input_batch.numel()\n",
        "\n",
        "val_tokens = 0\n",
        "for input_batch, target_batch in val_loader:\n",
        "    val_tokens += input_batch.numel()\n",
        "\n",
        "print(\"Training tokens:\", train_tokens)\n",
        "print(\"Validation tokens:\", val_tokens)\n",
        "print(\"All tokens:\", train_tokens + val_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c3085e8-665e-48eb-bb41-cdde61537e06",
      "metadata": {
        "id": "5c3085e8-665e-48eb-bb41-cdde61537e06"
      },
      "source": [
        "- Next, let's calculate the initial loss before we start training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0691332-84d0-48b3-b462-a885ddeb4fca",
      "metadata": {
        "id": "f0691332-84d0-48b3-b462-a885ddeb4fca"
      },
      "source": [
        "- If you have a machine with a CUDA-supported GPU, the LLM will train on the GPU without making any changes to the code\n",
        "- Via the `device` setting, we ensure that the data is loaded onto the same device as the LLM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "56f5b0c9-1065-4d67-98b9-010e42fc1e2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56f5b0c9-1065-4d67-98b9-010e42fc1e2a",
        "outputId": "dae6d524-d9f7-48b3-ca19-bddad2a204fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 10.987583266364204\n",
            "Validation loss: 10.981104850769043\n"
          ]
        }
      ],
      "source": [
        "from supplementary import calc_loss_loader\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
        "\n",
        "\n",
        "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
        "\n",
        "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
        "    train_loss = calc_loss_loader(train_loader, model, device)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device)\n",
        "\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9339f8d-00cb-4206-af67-58c32bd72055",
      "metadata": {
        "id": "b9339f8d-00cb-4206-af67-58c32bd72055"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "# 4.3 Training an LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "652a4cf4-e98f-46d9-bdec-60e7ccb8d6bd",
      "metadata": {
        "id": "652a4cf4-e98f-46d9-bdec-60e7ccb8d6bd"
      },
      "source": [
        "- In this section, we finally implement the code for training the LLM\n",
        "\n",
        "<img src=\"https://github.com/bioproj/LLM-workshop-2024/blob/main/04_pretraining/figures/04.png?raw=1\" width=700px>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "Mtp4gY0ZO-qq",
      "metadata": {
        "id": "Mtp4gY0ZO-qq"
      },
      "outputs": [],
      "source": [
        "from supplementary import (\n",
        "    calc_loss_batch,\n",
        "    evaluate_model,\n",
        "    generate_and_print_sample\n",
        ")\n",
        "\n",
        "\n",
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a301b333-b9d4-4eeb-a212-3a9874e3ac47",
      "metadata": {
        "id": "a301b333-b9d4-4eeb-a212-3a9874e3ac47"
      },
      "source": [
        "- Now, let's train the LLM using the training function defined above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "3422000b-7aa2-485b-92df-99372cd22311",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3422000b-7aa2-485b-92df-99372cd22311",
        "outputId": "32f067af-e704-4186-fa7e-2d8937c56a48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 9.818, Val loss 9.930\n",
            "Ep 1 (Step 000005): Train loss 8.066, Val loss 8.336\n",
            "Every effort moves you,,,,,,,,,,,,.                                     \n",
            "Ep 2 (Step 000010): Train loss 6.623, Val loss 7.053\n",
            "Ep 2 (Step 000015): Train loss 6.047, Val loss 6.605\n",
            "Every effort moves you, and,, and,,,,,,, and,.                                   \n",
            "Ep 3 (Step 000020): Train loss 5.532, Val loss 6.507\n",
            "Ep 3 (Step 000025): Train loss 5.399, Val loss 6.389\n",
            "Every effort moves you, and to the to the of the to the, and I had. Gis, and, and, and, and, and, and I had the, and, and, and, and, and, and, and, and, and\n",
            "Ep 4 (Step 000030): Train loss 4.895, Val loss 6.280\n",
            "Ep 4 (Step 000035): Train loss 4.648, Val loss 6.304\n",
            "Every effort moves you.  \"I the picture.                    \"I\"I the picture\"I had the the honour of the picture and I had been the picture of\n",
            "Ep 5 (Step 000040): Train loss 4.023, Val loss 6.165\n",
            "Every effort moves you know                                                 \n",
            "Ep 6 (Step 000045): Train loss 3.625, Val loss 6.172\n",
            "Ep 6 (Step 000050): Train loss 3.045, Val loss 6.144\n",
            "Every effort moves you know the was his a little the.  \"I had the last word.           \"Oh, and I had a little.   \"I looked, and I had a little of\n",
            "Ep 7 (Step 000055): Train loss 2.948, Val loss 6.183\n",
            "Ep 7 (Step 000060): Train loss 2.230, Val loss 6.128\n",
            "Every effort moves you know the picture to have been too--I felt, and Mrs.  \"I was no--and the fact, and that, and I was his pictures.  \"I looked up his pictures--and--because he was a little\n",
            "Ep 8 (Step 000065): Train loss 1.774, Val loss 6.162\n",
            "Ep 8 (Step 000070): Train loss 1.475, Val loss 6.229\n",
            "Every effort moves you?\"  \"Yes--I glanced after him, and uncertain.  \"I looked up, and the fact, and to see a smile behind his close grayish beard--as if he had the donkey. \"There were days when I\n",
            "Ep 9 (Step 000075): Train loss 1.135, Val loss 6.268\n",
            "Ep 9 (Step 000080): Train loss 0.858, Val loss 6.298\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word.    \"I looked, and that, and I remember getting off a prodigious phrase about the honour being _mine_--because he's the first\n",
            "Ep 10 (Step 000085): Train loss 0.627, Val loss 6.382\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 10\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "139885c4-40ed-4765-b307-511d5a967fcd",
      "metadata": {
        "id": "139885c4-40ed-4765-b307-511d5a967fcd"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "0WSRu2i0iHJE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "0WSRu2i0iHJE",
        "outputId": "d57a0170-111f-4830-bc73-89ef67f83de8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from supplementary import plot_losses\n",
        "\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bc83ded-5f80-4e1c-bf4d-ccb59999d995",
      "metadata": {
        "id": "8bc83ded-5f80-4e1c-bf4d-ccb59999d995"
      },
      "source": [
        "- Looking at the results above, we can see that the model starts out generating incomprehensible strings of words, whereas towards the end, it's able to produce grammatically more or less correct sentences\n",
        "- However, based on the training and validation set losses, we can see that the model starts overfitting\n",
        "- If we were to check a few passages it writes towards the end, we would find that they are contained in the training set verbatim -- it simply memorizes the training data\n",
        "\n",
        "- There are decoding strategies (not covered in this workshop) that can mitigate this memorization by a certain degree\n",
        "- Also note that the overfitting here occurs because we have a very, very small training set, and we iterate over it so many times\n",
        "  - The LLM training here primarily serves educational purposes; we mainly want to see that the model can learn to produce coherent text\n",
        "  - Instead of spending weeks or months on training this model on vast amounts of expensive hardware, we load pretrained weights later"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c58ebc3a-34d1-4efe-94a0-ef5bec732162",
      "metadata": {
        "id": "c58ebc3a-34d1-4efe-94a0-ef5bec732162"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "# Exercise 1: Generate text from the pretrained LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b25558c3-a4f4-48de-a18e-ed63ff9ee02a",
      "metadata": {
        "id": "b25558c3-a4f4-48de-a18e-ed63ff9ee02a"
      },
      "source": [
        "- Use the model to generate new text (HINT: scroll up to see how we generated text before)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d62ff8c-78ea-47fa-b02d-9313531cb4df",
      "metadata": {
        "id": "1d62ff8c-78ea-47fa-b02d-9313531cb4df"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "# Exercise 2: Load the pretrained model in a new session"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a62addc-41ed-4853-8aec-365ef4611f79",
      "metadata": {
        "id": "3a62addc-41ed-4853-8aec-365ef4611f79"
      },
      "source": [
        "- Open a new Python session or Jupyter notebook and load the model there"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f4b25e3-d1aa-4559-897c-36588bba2057",
      "metadata": {
        "id": "7f4b25e3-d1aa-4559-897c-36588bba2057"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "# Exercise 3 (Optional): Train the LLM on your own favorite texts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11f349d5-35e4-4502-8b86-ab57b5ca2f0c",
      "metadata": {
        "id": "11f349d5-35e4-4502-8b86-ab57b5ca2f0c"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "# Solution to Exercise 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Imports from a local file\n",
        "from supplementary import GPTModel\n",
        "\n",
        "\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "state_dict = torch.load(\"model.pth\", map_location=device)\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval();\n",
        "\n",
        "start_context = \"Every effort moves you\"\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "device = torch.device( \"cpu\")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(start_context, tokenizer).to(device),\n",
        "    max_new_tokens=30,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ],
      "metadata": {
        "id": "i4lFSyl4g4Yi",
        "outputId": "05f19de8-1cab-4b4a-dd82-04db54105f5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "i4lFSyl4g4Yi",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-70-dc8f31f6dae6>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(\"model.pth\", map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " Every effort moves you?\"\n",
            "\n",
            "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
            "\n",
            "He laughed again, and\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx=text_to_token_ids(start_context, tokenizer).to(device)\n",
        "for _ in range(30):\n",
        "   with torch.no_grad():\n",
        "\n",
        "      # Crop current context if it exceeds the supported context size\n",
        "      # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "      # then only the last 5 tokens are used as context\n",
        "      idx_cond = idx[:, -GPT_CONFIG_124M[\"context_length\"]:]\n",
        "\n",
        "      # Get the predictions\n",
        "      with torch.no_grad():\n",
        "          logits = model(idx_cond)\n",
        "\n",
        "      # Focus only on the last time step\n",
        "      # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
        "      logits = logits[:, -1, :]\n",
        "\n",
        "      # Apply softmax to get probabilities\n",
        "      probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
        "\n",
        "      # Get the idx of the vocab entry with the highest probability value\n",
        "      idx_next = torch.argmax(probas, dim=-1).unsqueeze(0)  # (batch, 1)\n",
        "\n",
        "      # Append sampled index to the running sequence\n",
        "      idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "      # print(token_ids_to_text(idx, tokenizer))\n",
        "      # print()\n",
        "      new_text = token_ids_to_text(idx_next, tokenizer)\n",
        "      print(new_text, end=\"\", flush=True)\n"
      ],
      "metadata": {
        "id": "U8p3ZEXjlBDl",
        "outputId": "976ae568-57dc-43ab-823e-8d3e20004adb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "U8p3ZEXjlBDl",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?\"\n",
            "\n",
            "\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
            "\n",
            "He laughed again, and"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "# 加载 Hugging Face 预训练模型架构\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "\n",
        "# 加载 `.pth` 权重到 Hugging Face 兼容模型\n",
        "model.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "# 保存为 Hugging Face 格式\n",
        "model.save_pretrained(\"huggingface_model\")"
      ],
      "metadata": {
        "id": "0ar7nRkBkOTA",
        "outputId": "18a7190f-2860-40ad-921d-db7baa8cb732",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0ar7nRkBkOTA",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx=text_to_token_ids(start_context, tokenizer).to(device)"
      ],
      "metadata": {
        "id": "0-QNJdnrmDle",
        "outputId": "2a79ac47-3c49-4124-868a-2988249f0f52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "id": "0-QNJdnrmDle",
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'allowed_special'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-e49cb2a76cdd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_to_token_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-88aba1e42bdf>\u001b[0m in \u001b[0;36mtext_to_token_ids\u001b[0;34m(text, tokenizer)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtext_to_token_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_special\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'<|endoftext|>'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mencoded_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# add batch dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mencoded_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, padding_side, return_tensors, **kwargs)\u001b[0m\n\u001b[1;32m   2625\u001b[0m                 method).\n\u001b[1;32m   2626\u001b[0m         \"\"\"\n\u001b[0;32m-> 2627\u001b[0;31m         encoded_inputs = self.encode_plus(\n\u001b[0m\u001b[1;32m   2628\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3044\u001b[0m         )\n\u001b[1;32m   3045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3046\u001b[0;31m         return self._encode_plus(\n\u001b[0m\u001b[1;32m   3047\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3048\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gpt2/tokenization_gpt2_fast.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m         )\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encode_plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_directory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_prefix\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m     ) -> BatchEncoding:\n\u001b[1;32m    599\u001b[0m         \u001b[0mbatched_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         batched_output = self._batch_encode_plus(\n\u001b[0m\u001b[1;32m    601\u001b[0m             \u001b[0mbatched_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0mis_split_into_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_split_into_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gpt2/tokenization_gpt2_fast.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m         )\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_encode_plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_encode_plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mBatchEncoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'allowed_special'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "f564c82a-49f7-46da-ad78-b9cb846eb5e3",
      "metadata": {
        "id": "f564c82a-49f7-46da-ad78-b9cb846eb5e3",
        "outputId": "22d75583-85fa-4c6a-8268-6157c19dc76b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'allowed_special'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-2f42faa1141c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Once upon a time\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_to_token_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# 逐步生成文本（流式输出）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-88aba1e42bdf>\u001b[0m in \u001b[0;36mtext_to_token_ids\u001b[0;34m(text, tokenizer)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtext_to_token_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_special\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'<|endoftext|>'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mencoded_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# add batch dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mencoded_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, padding_side, return_tensors, **kwargs)\u001b[0m\n\u001b[1;32m   2625\u001b[0m                 method).\n\u001b[1;32m   2626\u001b[0m         \"\"\"\n\u001b[0;32m-> 2627\u001b[0;31m         encoded_inputs = self.encode_plus(\n\u001b[0m\u001b[1;32m   2628\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3044\u001b[0m         )\n\u001b[1;32m   3045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3046\u001b[0;31m         return self._encode_plus(\n\u001b[0m\u001b[1;32m   3047\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3048\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gpt2/tokenization_gpt2_fast.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m         )\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encode_plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_directory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_prefix\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m     ) -> BatchEncoding:\n\u001b[1;32m    599\u001b[0m         \u001b[0mbatched_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         batched_output = self._batch_encode_plus(\n\u001b[0m\u001b[1;32m    601\u001b[0m             \u001b[0mbatched_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0mis_split_into_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_split_into_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gpt2/tokenization_gpt2_fast.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m         )\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_encode_plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_encode_plus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mBatchEncoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: PreTrainedTokenizerFast._batch_encode_plus() got an unexpected keyword argument 'allowed_special'"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModel\n",
        "model = AutoModel.from_pretrained(\"huggingface_model\")\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"huggingface_model\")\n",
        "# 输入文本\n",
        "input_text = \"Once upon a time\"\n",
        "# input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "input_ids=text_to_token_ids(input_text, tokenizer).to(device)\n",
        "\n",
        "# 逐步生成文本（流式输出）\n",
        "max_new_tokens = 50\n",
        "output_ids = input_ids\n",
        "\n",
        "for _ in range(max_new_tokens):\n",
        "    with torch.no_grad():\n",
        "        outputs = model(output_ids)\n",
        "        next_token = torch.argmax(outputs.logits[:, -1, :], dim=-1).unsqueeze(0)\n",
        "        # output_ids = torch.cat([output_ids, next_token], dim=1)\n",
        "\n",
        "        # 解码并打印新增 token\n",
        "        # new_text = tokenizer.decode(next_token[0])\n",
        "        print(next_token[0], end=\"\", flush=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bXhAMTxPbUMP",
        "outputId": "f758c386-8b69-4d3e-8794-45f733e607bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bXhAMTxPbUMP",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "?\"\n",
            "\n",
            "\"Yes--quite insensible to"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(10):\n",
        "    with torch.no_grad():\n",
        "        outputs = model(output_ids)\n",
        "        next_token = torch.argmax(outputs.logits[:, -1, :], dim=-1).unsqueeze(0)\n",
        "        output_ids = torch.cat([output_ids, next_token], dim=1)\n",
        "\n",
        "        # 解码并打印新增 token\n",
        "        new_text = tokenizer.decode(next_token[0])\n",
        "        print(new_text, end=\"\", flush=True)"
      ],
      "metadata": {
        "id": "6nVET-tcgBLs"
      },
      "id": "6nVET-tcgBLs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "3e9d58e1-afba-44c7-9f82-7516adff359d",
      "metadata": {
        "id": "3e9d58e1-afba-44c7-9f82-7516adff359d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b64b3b1f-c8d3-4755-a926-dc86eeae0ba0",
      "metadata": {
        "id": "b64b3b1f-c8d3-4755-a926-dc86eeae0ba0"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "# Solution to Exercise 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "a998656c-3615-4673-a9f9-c8eefb6b6611",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a998656c-3615-4673-a9f9-c8eefb6b6611",
        "outputId": "94b7a8a3-7f34-4e15-c1c1-04ff5e886170"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-38d44f6c3178>:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Imports from a local file\n",
        "from supplementary import GPTModel\n",
        "\n",
        "\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"model.pth\"))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "BDU-0R2sdaw0"
      },
      "id": "BDU-0R2sdaw0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"model3\")"
      ],
      "metadata": {
        "id": "4aXv6s_7c1wU",
        "outputId": "e7321a04-60d4-44ba-ce86-3c7c577a0a24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "id": "4aXv6s_7c1wU",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'GPTModel' object has no attribute 'save_pretrained'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-548a14dd1f1a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1931\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1932\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1933\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'GPTModel' object has no attribute 'save_pretrained'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from litgpt import LLM\n",
        "\n",
        "llm = LLM.load(\"microsoft/phi-2\")\n",
        "\n",
        "llm.generate(\"What do Llamas eat?\")"
      ],
      "metadata": {
        "id": "c6zduMxqbY6T",
        "outputId": "b3f2c80a-183b-4fc0-b70e-3bc6eeda550b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522,
          "referenced_widgets": [
            "b4e9ad891d4c487a8f1c053ed3cc3ada",
            "32f0c094ac2f428a8d146e0b0219d98b",
            "f338ba9ca2bc4205846b7c94886ac246",
            "b049d42da41749c59c472ebfc048fff9",
            "35a74fb21fc240cd90c3782336940c1e",
            "1b1423d24b354fa19e0a18c7be488535",
            "701d8edba1d043c399e743e2e63a0934",
            "bcbbec15a0e144168faa9d6afbc6aee7",
            "6fae3dedefb146b0b090f6d949dc8598",
            "99aa790a763b44b69529e08ce1b0816e",
            "81a41596d4684fa7b84a7f7159d50ac5",
            "a2412a71ea1246fc8fe17543461d8c14",
            "2bc2f1662b7c4c84b2cc03c183c875db",
            "19c555d3c2e5478d807d0a09b6a0017c",
            "3edafa0b9cda464fa46dcf8d751f5088",
            "19ab5b4daf2c474f9fefeee4098e27ee",
            "f020aa0d225f4213a3009b6a2d0ff4cc",
            "f0f6394df4fd4c5482e166890631c5e8",
            "0a8bc4ec354d469a9e097c7074b7c03e",
            "1889d195a9ea49b580c0ff40fcc286c2",
            "0d4cab1a6c9a4c4cac06c1a3765a4524",
            "df511ee03dc745f0b2bc1c30c8ffc9c1",
            "234e34b6657d40bcacf37727949cf2a5",
            "6259950633a143cab6d798c408e24eb5",
            "4b0467d3f421404ab997665f6f911fe3",
            "99da7172afe04f80a43dca31327640c7",
            "8cda9e4f9a8248878949593c3c9c9c4b",
            "7c2ac686186b41b1a39be09383cf1f9e",
            "1376c6a4ecc045ba96f8727c02068fb6",
            "6f0a42fa741343c1894fa6c637c87662",
            "d93f0be48628437389706b104abec276",
            "e142dabc209c4bd397bc01783ccbd1e6",
            "f7d07c6a463a426fa8d479b7ca6a2ce7",
            "ccc30e61c0b145d782fc6dced0f1b57b",
            "9d18902b74574e259ffe316220e5f595",
            "c2a24098a8d94b8ca04cb749ce214340",
            "fa285ddd600c41218128c5839d06a16a",
            "d1fa1e76806c4dbd96e23e2b1a0628c0",
            "41015f2308394971a2b24d343a342545",
            "7c0137696ab3497aa71fb3da14bdedf8",
            "abdc31d06e9f40a1b4031a3972044274",
            "2330d3841c0343efadc4d5e5a4134516",
            "8f9ea843de2f4489a076ee324fcf2b52",
            "14ee3d09571d474385fb80d32dc61dbf",
            "6826127d30e448d9a0d95408282360ee",
            "ca2ed40f3b034221b70daf42f75b5725",
            "62607fe10b67402881483d71e4661a06",
            "867a329717924daf839fb499a843c283",
            "8838fdf3e44d4a48b0efa38b12d7045a",
            "d0f434674c3f41d0a465d0fd889abf52",
            "6e61db13a2ed4cd7821339e08c96715b",
            "20eb1582ae2a4883940ccc2ea43b9238",
            "2d2dc58145564c62b00e97b8d564aa64",
            "d45acfd1dc854996bbb15fe6c33818b9",
            "5cef47da19d348d99350c0deee2d6211",
            "479a45ecdd2b447ab3c1532db1e2c7ce",
            "11544e06ef1849cbac1d34b92d85e44e",
            "6e1a069af9e346edbbe869a864ef728a",
            "b6858956ffbd42669d26b2762564cc68",
            "4694f2392ba144a3adb7613ea067ccff",
            "2954dffcffe5425aa6741fe2c9a44ff9",
            "22c67c3891af4b988b5a9b2f3c7a5e3d",
            "9d4928d11d304162ae2ce743cd52f097",
            "335ddd6e59d54cff916c3f4c1fd9b733",
            "6bac358f0699421ba931da0708695b63",
            "c548a96e83b04b32b75deedbfe0ee486",
            "d2131cd6ba9b463e94163e1b01f4f44c",
            "4101a19133e444e69f0a2dff0ec81a52",
            "92d17d8b7c984011a0249b18fc092202",
            "c48f3cae97984ca992ac892580ed3f8a",
            "e256ed31563f4568b1ab76861a2ef35d",
            "b07b052a24f241c69a6fb5da241edad8",
            "4077a2c54c8e4d06aac0451cd379bdc9",
            "10e3891e43c54a5c98d68ac8be3788b2",
            "1bd3be0f0802494da49bd28849d1f8fa",
            "16cc295b345b41c580b9d7a8d2c90d4d",
            "db9a9d4b822d49f7b5af45f5b6e719c9"
          ]
        }
      },
      "id": "c6zduMxqbY6T",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting HF_HUB_ENABLE_HF_TRANSFER=1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4e9ad891d4c487a8f1c053ed3cc3ada"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2412a71ea1246fc8fe17543461d8c14"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "234e34b6657d40bcacf37727949cf2a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ccc30e61c0b145d782fc6dced0f1b57b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/35.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6826127d30e448d9a0d95408282360ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "479a45ecdd2b447ab3c1532db1e2c7ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2131cd6ba9b463e94163e1b01f4f44c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting checkpoint files to LitGPT format.\n",
            "{'checkpoint_dir': PosixPath('checkpoints/microsoft/phi-2'),\n",
            " 'debug_mode': False,\n",
            " 'dtype': None,\n",
            " 'model_name': None}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading weights: model-00002-of-00002.safetensors: 100%|██████████| 00:47<00:00,  2.12it/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving converted checkpoint to checkpoints/microsoft/phi-2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Noun\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.generate(\"What do Llamas eat?\")"
      ],
      "metadata": {
        "id": "8eAfQcL-bY83",
        "outputId": "0d108961-550e-46b4-c927-7fdcd627bb24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "id": "8eAfQcL-bY83",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Llamas mainly eat grass, shrubs, leaves, and herbs. They may also consume small insects, fruits, vegetables, and flowers. Some llamas may occasionally eat hay or grains to supplement their diet.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# 加载模型和分词器\n",
        "model_name = \"gpt2\"  # 可换成更强的模型，比如 \"EleutherAI/gpt-neo-2.7B\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# 输入文本\n",
        "input_text = \"Once upon a time\"\n",
        "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "# 逐步生成文本（流式输出）\n",
        "max_new_tokens = 50\n",
        "output_ids = input_ids\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fkREsImCbY_Q",
        "outputId": "74fa20d8-0214-40c4-d1b5-53748a59607d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "fkREsImCbY_Q",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ", the world was a place of great beauty and great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the world was a place of great danger"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(max_new_tokens):\n",
        "    with torch.no_grad():\n",
        "        outputs = model(output_ids)\n",
        "        next_token = torch.argmax(outputs.logits[:, -1, :], dim=-1).unsqueeze(0)\n",
        "        output_ids = torch.cat([output_ids, next_token], dim=1)\n",
        "\n",
        "        # 解码并打印新增 token\n",
        "        new_text = tokenizer.decode(next_token[0])\n",
        "        print(new_text, end=\"\", flush=True)"
      ],
      "metadata": {
        "id": "LiQ5p-46fGQn",
        "outputId": "303d5acf-5276-4342-f18d-0fe76ed01f60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LiQ5p-46fGQn",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ". The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextStreamer\n",
        "\n",
        "streamer = TextStreamer(tokenizer)  # 创建流式解码器\n",
        "\n",
        "input_text = \"Once upon a time\"\n",
        "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
        "\n",
        "# 直接使用 streamer 进行流式生成\n",
        "model.generate(input_ids, max_new_tokens=50, streamer=streamer)"
      ],
      "metadata": {
        "id": "Cre-fu-QbZBe",
        "outputId": "1a82ea8c-85c2-4ec4-ff67-00eaf3e46f57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Cre-fu-QbZBe",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time, the world was a place of great beauty and great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the world was a place of great danger\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[7454, 2402,  257,  640,   11,  262,  995,  373,  257, 1295,  286, 1049,\n",
              "         8737,  290, 1049, 3514,   13,  383,  995,  373,  257, 1295,  286, 1049,\n",
              "         3514,   11,  290,  262,  995,  373,  257, 1295,  286, 1049, 3514,   13,\n",
              "          383,  995,  373,  257, 1295,  286, 1049, 3514,   11,  290,  262,  995,\n",
              "          373,  257, 1295,  286, 1049, 3514]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MV95JVXtbZNm"
      },
      "id": "MV95JVXtbZNm",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b4e9ad891d4c487a8f1c053ed3cc3ada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32f0c094ac2f428a8d146e0b0219d98b",
              "IPY_MODEL_f338ba9ca2bc4205846b7c94886ac246",
              "IPY_MODEL_b049d42da41749c59c472ebfc048fff9"
            ],
            "layout": "IPY_MODEL_35a74fb21fc240cd90c3782336940c1e"
          }
        },
        "32f0c094ac2f428a8d146e0b0219d98b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b1423d24b354fa19e0a18c7be488535",
            "placeholder": "​",
            "style": "IPY_MODEL_701d8edba1d043c399e743e2e63a0934",
            "value": "config.json: 100%"
          }
        },
        "f338ba9ca2bc4205846b7c94886ac246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcbbec15a0e144168faa9d6afbc6aee7",
            "max": 735,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6fae3dedefb146b0b090f6d949dc8598",
            "value": 735
          }
        },
        "b049d42da41749c59c472ebfc048fff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99aa790a763b44b69529e08ce1b0816e",
            "placeholder": "​",
            "style": "IPY_MODEL_81a41596d4684fa7b84a7f7159d50ac5",
            "value": " 735/735 [00:00&lt;00:00, 71.6kB/s]"
          }
        },
        "35a74fb21fc240cd90c3782336940c1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b1423d24b354fa19e0a18c7be488535": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "701d8edba1d043c399e743e2e63a0934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcbbec15a0e144168faa9d6afbc6aee7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fae3dedefb146b0b090f6d949dc8598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "99aa790a763b44b69529e08ce1b0816e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81a41596d4684fa7b84a7f7159d50ac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2412a71ea1246fc8fe17543461d8c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2bc2f1662b7c4c84b2cc03c183c875db",
              "IPY_MODEL_19c555d3c2e5478d807d0a09b6a0017c",
              "IPY_MODEL_3edafa0b9cda464fa46dcf8d751f5088"
            ],
            "layout": "IPY_MODEL_19ab5b4daf2c474f9fefeee4098e27ee"
          }
        },
        "2bc2f1662b7c4c84b2cc03c183c875db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f020aa0d225f4213a3009b6a2d0ff4cc",
            "placeholder": "​",
            "style": "IPY_MODEL_f0f6394df4fd4c5482e166890631c5e8",
            "value": "generation_config.json: 100%"
          }
        },
        "19c555d3c2e5478d807d0a09b6a0017c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a8bc4ec354d469a9e097c7074b7c03e",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1889d195a9ea49b580c0ff40fcc286c2",
            "value": 124
          }
        },
        "3edafa0b9cda464fa46dcf8d751f5088": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d4cab1a6c9a4c4cac06c1a3765a4524",
            "placeholder": "​",
            "style": "IPY_MODEL_df511ee03dc745f0b2bc1c30c8ffc9c1",
            "value": " 124/124 [00:00&lt;00:00, 13.6kB/s]"
          }
        },
        "19ab5b4daf2c474f9fefeee4098e27ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f020aa0d225f4213a3009b6a2d0ff4cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0f6394df4fd4c5482e166890631c5e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a8bc4ec354d469a9e097c7074b7c03e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1889d195a9ea49b580c0ff40fcc286c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d4cab1a6c9a4c4cac06c1a3765a4524": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df511ee03dc745f0b2bc1c30c8ffc9c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "234e34b6657d40bcacf37727949cf2a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6259950633a143cab6d798c408e24eb5",
              "IPY_MODEL_4b0467d3f421404ab997665f6f911fe3",
              "IPY_MODEL_99da7172afe04f80a43dca31327640c7"
            ],
            "layout": "IPY_MODEL_8cda9e4f9a8248878949593c3c9c9c4b"
          }
        },
        "6259950633a143cab6d798c408e24eb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c2ac686186b41b1a39be09383cf1f9e",
            "placeholder": "​",
            "style": "IPY_MODEL_1376c6a4ecc045ba96f8727c02068fb6",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "4b0467d3f421404ab997665f6f911fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f0a42fa741343c1894fa6c637c87662",
            "max": 4995584424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d93f0be48628437389706b104abec276",
            "value": 4995583948
          }
        },
        "99da7172afe04f80a43dca31327640c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e142dabc209c4bd397bc01783ccbd1e6",
            "placeholder": "​",
            "style": "IPY_MODEL_f7d07c6a463a426fa8d479b7ca6a2ce7",
            "value": " 5.00G/5.00G [00:44&lt;00:00, 456MB/s]"
          }
        },
        "8cda9e4f9a8248878949593c3c9c9c4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c2ac686186b41b1a39be09383cf1f9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1376c6a4ecc045ba96f8727c02068fb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f0a42fa741343c1894fa6c637c87662": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d93f0be48628437389706b104abec276": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e142dabc209c4bd397bc01783ccbd1e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7d07c6a463a426fa8d479b7ca6a2ce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccc30e61c0b145d782fc6dced0f1b57b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d18902b74574e259ffe316220e5f595",
              "IPY_MODEL_c2a24098a8d94b8ca04cb749ce214340",
              "IPY_MODEL_fa285ddd600c41218128c5839d06a16a"
            ],
            "layout": "IPY_MODEL_d1fa1e76806c4dbd96e23e2b1a0628c0"
          }
        },
        "9d18902b74574e259ffe316220e5f595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41015f2308394971a2b24d343a342545",
            "placeholder": "​",
            "style": "IPY_MODEL_7c0137696ab3497aa71fb3da14bdedf8",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "c2a24098a8d94b8ca04cb749ce214340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abdc31d06e9f40a1b4031a3972044274",
            "max": 563832976,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2330d3841c0343efadc4d5e5a4134516",
            "value": 563832923
          }
        },
        "fa285ddd600c41218128c5839d06a16a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f9ea843de2f4489a076ee324fcf2b52",
            "placeholder": "​",
            "style": "IPY_MODEL_14ee3d09571d474385fb80d32dc61dbf",
            "value": " 564M/564M [00:05&lt;00:00, 56.0MB/s]"
          }
        },
        "d1fa1e76806c4dbd96e23e2b1a0628c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41015f2308394971a2b24d343a342545": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c0137696ab3497aa71fb3da14bdedf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abdc31d06e9f40a1b4031a3972044274": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2330d3841c0343efadc4d5e5a4134516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f9ea843de2f4489a076ee324fcf2b52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14ee3d09571d474385fb80d32dc61dbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6826127d30e448d9a0d95408282360ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca2ed40f3b034221b70daf42f75b5725",
              "IPY_MODEL_62607fe10b67402881483d71e4661a06",
              "IPY_MODEL_867a329717924daf839fb499a843c283"
            ],
            "layout": "IPY_MODEL_8838fdf3e44d4a48b0efa38b12d7045a"
          }
        },
        "ca2ed40f3b034221b70daf42f75b5725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0f434674c3f41d0a465d0fd889abf52",
            "placeholder": "​",
            "style": "IPY_MODEL_6e61db13a2ed4cd7821339e08c96715b",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "62607fe10b67402881483d71e4661a06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20eb1582ae2a4883940ccc2ea43b9238",
            "max": 35716,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d2dc58145564c62b00e97b8d564aa64",
            "value": 35716
          }
        },
        "867a329717924daf839fb499a843c283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d45acfd1dc854996bbb15fe6c33818b9",
            "placeholder": "​",
            "style": "IPY_MODEL_5cef47da19d348d99350c0deee2d6211",
            "value": " 35.7k/35.7k [00:00&lt;00:00, 3.45MB/s]"
          }
        },
        "8838fdf3e44d4a48b0efa38b12d7045a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0f434674c3f41d0a465d0fd889abf52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e61db13a2ed4cd7821339e08c96715b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20eb1582ae2a4883940ccc2ea43b9238": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d2dc58145564c62b00e97b8d564aa64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d45acfd1dc854996bbb15fe6c33818b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cef47da19d348d99350c0deee2d6211": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "479a45ecdd2b447ab3c1532db1e2c7ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11544e06ef1849cbac1d34b92d85e44e",
              "IPY_MODEL_6e1a069af9e346edbbe869a864ef728a",
              "IPY_MODEL_b6858956ffbd42669d26b2762564cc68"
            ],
            "layout": "IPY_MODEL_4694f2392ba144a3adb7613ea067ccff"
          }
        },
        "11544e06ef1849cbac1d34b92d85e44e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2954dffcffe5425aa6741fe2c9a44ff9",
            "placeholder": "​",
            "style": "IPY_MODEL_22c67c3891af4b988b5a9b2f3c7a5e3d",
            "value": "tokenizer.json: 100%"
          }
        },
        "6e1a069af9e346edbbe869a864ef728a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d4928d11d304162ae2ce743cd52f097",
            "max": 2114924,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_335ddd6e59d54cff916c3f4c1fd9b733",
            "value": 2114924
          }
        },
        "b6858956ffbd42669d26b2762564cc68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bac358f0699421ba931da0708695b63",
            "placeholder": "​",
            "style": "IPY_MODEL_c548a96e83b04b32b75deedbfe0ee486",
            "value": " 2.11M/2.11M [00:00&lt;00:00, 2.48MB/s]"
          }
        },
        "4694f2392ba144a3adb7613ea067ccff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2954dffcffe5425aa6741fe2c9a44ff9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22c67c3891af4b988b5a9b2f3c7a5e3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d4928d11d304162ae2ce743cd52f097": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "335ddd6e59d54cff916c3f4c1fd9b733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6bac358f0699421ba931da0708695b63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c548a96e83b04b32b75deedbfe0ee486": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2131cd6ba9b463e94163e1b01f4f44c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4101a19133e444e69f0a2dff0ec81a52",
              "IPY_MODEL_92d17d8b7c984011a0249b18fc092202",
              "IPY_MODEL_c48f3cae97984ca992ac892580ed3f8a"
            ],
            "layout": "IPY_MODEL_e256ed31563f4568b1ab76861a2ef35d"
          }
        },
        "4101a19133e444e69f0a2dff0ec81a52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b07b052a24f241c69a6fb5da241edad8",
            "placeholder": "​",
            "style": "IPY_MODEL_4077a2c54c8e4d06aac0451cd379bdc9",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "92d17d8b7c984011a0249b18fc092202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10e3891e43c54a5c98d68ac8be3788b2",
            "max": 7339,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bd3be0f0802494da49bd28849d1f8fa",
            "value": 7339
          }
        },
        "c48f3cae97984ca992ac892580ed3f8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16cc295b345b41c580b9d7a8d2c90d4d",
            "placeholder": "​",
            "style": "IPY_MODEL_db9a9d4b822d49f7b5af45f5b6e719c9",
            "value": " 7.34k/7.34k [00:00&lt;00:00, 419kB/s]"
          }
        },
        "e256ed31563f4568b1ab76861a2ef35d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b07b052a24f241c69a6fb5da241edad8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4077a2c54c8e4d06aac0451cd379bdc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10e3891e43c54a5c98d68ac8be3788b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bd3be0f0802494da49bd28849d1f8fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "16cc295b345b41c580b9d7a8d2c90d4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db9a9d4b822d49f7b5af45f5b6e719c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}